{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d08233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' شاہد آفریدی کے لیے الوداعی میچ نہیں تقریب', ' ’آفریدی کو الوداعی میچ نہ دینا بدقسمتی ہے‘']\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Apr 30 03:08:43 2023\n",
    "\n",
    "@author: Mohammad Rafay\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "import re\n",
    "import os\n",
    "import glob\n",
    "from tkinter import *\n",
    "from urduhack import normalize\n",
    "import subprocess\n",
    "\n",
    "stop_words = frozenset(\"\"\"\n",
    " آ آئی آئیں آئے آتا آتی آتے آس آنا آنی آنے آپ آیا ابھی از اس اسی اسے البتہ\n",
    " الف ان انہوں انہی انہیں اور اپ اپنا اپنی اپنے اکثر اگر اگرچہ ایسا ایسی ایسے ایک اے بار بارے\n",
    " باوجود باہر بعض بغیر بلکہ بن بنا بناؤ بند بڑی بھر بھریں بھی بہت بیس بے تا تاکہ تب تجھ\n",
    " تجھے تحت تر تم تمہارا تمہاری تمہارے تمہیں تو تک تھا تھی تھیں تھے تیری جا جاؤ جائیں جائے جاتا\n",
    " جاتی جاتے جانی جانے جب جبکہ جس جن جنہوں جنہیں جو جہاں جیسا جیسوں جیسی جیسے حالانکہ حالاں حصہ خالی\n",
    " خود درمیان دوران دوسرا دوسروں دوسری دوسرے دوں دکھائیں دی دیئے دیا دیتا دیتی دیتے دیر دینا دینی دینے\n",
    " دیکھو دیں دیے دے ذریعے رکھا رکھتا رکھتی رکھتے رکھنا رکھنی رکھنے رکھو رکھی رکھے رہ رہا رہتا رہتی رہتے\n",
    " رہنا رہنی رہنے رہو رہی رہیں رہے سا ساتھ سامنے سب سو سکا سکتا سکتے سی سے شاید صرف طرح\n",
    " طرف طور علاوہ عین لئے لا لائی لائے لاتا لاتی لاتے لانا لانی لانے لایا لو لوجی لوگ لوگوں لگ\n",
    " لگا لگتا لگتی لگی لگیں لگے لہذا لی لیا لیتا لیتی لیتے لیکن لیں لیے لے مجھ مجھے مزید مطابق\n",
    " مل مگر میرا میری میرے میں نا نہ نہیں نے وار واقعی والا والوں والی والے\n",
    " وجہ وغیرہ وہ وہاں وہی وہیں وی ویسے پایا پر پھر پیچھے چاہئے چاہتے چاہیئے چاہے چلا چلو چلیں چلے\n",
    " چونکہ چکی چکیں چکے ڈالنی ڈالنے ڈالے کئے کا کب کبھی کر کرتا کرتی کرتے کرنا کرنے کرو کریں کرے\n",
    " کس کسی کسے کم کو کوئی کون کونسا کچھ کہ کہا کہاں کہہ کہی کہیں کہے کی کیا کیسے کیونکہ\n",
    " کیوں کیے کے گئی گئے گا گویا گی گیا گے ہاں ہر ہم ہمارا ہماری ہمارے ہو ہوئی ہوئیں ہوئے\n",
    " ہوا ہوتا ہوتی ہوتیں ہوتے ہونا ہونگے ہونی ہونے ہوں ہی ہیں ہے یا یات یعنی یہ یہاں یہی یہیں\n",
    "\"\"\".split())\n",
    "\n",
    "\n",
    "\n",
    "\"Word Split\"\n",
    "def splitWords(headlines):\n",
    "    words = []\n",
    "    splitHL = []\n",
    "    for headline in headlines:  \n",
    "        words = re.split('\\W+',headline)\n",
    "        \n",
    "        splitHL.append(words)\n",
    "        words = [\"\"]\n",
    "    \n",
    "    return splitHL\n",
    "\n",
    "\"Word Tokenisation\"\n",
    "def tokeniseWords(wordList):\n",
    "    newWord = []\n",
    "    newWord = re.sub(r'[^\\w]', '', wordList)\n",
    "    #print(newWord)\n",
    "    return newWord\n",
    "\n",
    "\n",
    "\"Stop Word Removal\"\n",
    "def removeStopwords(jumla):    \n",
    "    emp = ''\n",
    "    finalwordsWoSW = []\n",
    "    for alfaz in jumla:\n",
    "        wordsWoSW = []\n",
    "        for lafz in alfaz:\n",
    "            if lafz in stop_words or lafz == emp:\n",
    "                continue\n",
    "            wordsWoSW.append(lafz)\n",
    "        \n",
    "        finalwordsWoSW.append(wordsWoSW)\n",
    "        del wordsWoSW \n",
    "        \n",
    "        \n",
    "    return finalwordsWoSW\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "END OF PRE PROCESSING\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\"Path of The Folders\"\n",
    "def dataFolders(path):\n",
    "    folders = []\n",
    "    foldferPath = path\n",
    "    for root, directories, files in os.walk(foldferPath):\n",
    "        for folder in directories:\n",
    "            folders.append(os.path.join(root,folder))\n",
    "        \n",
    "    return folders\n",
    "\n",
    "\n",
    "\"Read Title of the File\"\n",
    "def headlineReader(path):\n",
    "    headlines = []\n",
    "    extraWords = ['.doc','Urdu NEWS dataset\\\\','voa','bbc','dataset','entertainment','sports','miscleneous','politics','\\\\',\"'\"]\n",
    "    folderPath = path\n",
    "    files = [file for file in glob.glob(folderPath + \"**/*.DOC\", recursive=True)]\n",
    "    \n",
    "    for file in files:\n",
    "        file = re.sub(r'|'.join(map(re.escape, extraWords)), '', file)\n",
    "        headlines.append(file)\n",
    "        \n",
    "        \n",
    "    return headlines\n",
    "\n",
    "\n",
    "\"Path of the document\"\n",
    "def documentReturn(path):\n",
    "    headlines = []\n",
    "    extraWords = ['.doc','Urdu NEWS dataset\\\\','voa','bbc','dataset','entertainment','sports','miscleneous','politics','\\\\',\"'\"]\n",
    "    folderPath = path\n",
    "    files = [file for file in glob.glob(folderPath + \"**/*.DOC\", recursive=True)]\n",
    "    return files\n",
    "\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "PAPER ALGORITHM IMPLEMENTATION\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "\n",
    "def relatedNews(dataSet,inputNews):\n",
    "    relatedNewsList = []\n",
    "    t = 0.5\n",
    "    dataSetList = dataSet\n",
    "    ni = inputNews\n",
    "    sizeofDataSetList = len(dataSetList)\n",
    "    for j in range(0,sizeofDataSetList):\n",
    "        nj = dataSetList[j]\n",
    "        Sij = getSimilarityScore(ni,nj)\n",
    "        if Sij >= t:\n",
    "            relatedNewsList.append(nj)\n",
    "        \n",
    "    return relatedNewsList\n",
    "\n",
    "\n",
    "\"Similarity between input document(ith) and the jth document(document in the corpus)\"\n",
    "def getSimilarityScore(ni,nj):\n",
    "    tli = getTokensList(ni)\n",
    "    tlj = getTokensList(nj)\n",
    "    sti = len(tli)\n",
    "    stj = len(tlj)\n",
    "    Sij = 0\n",
    "    mij = 0\n",
    "    \n",
    "    for x in range(0,sti):\n",
    "        for y in range(0,stj):\n",
    "            if tli[x] == tlj[y]:\n",
    "                mij = mij + 1\n",
    "    \n",
    "    if mij > 0:\n",
    "        avg = (sti + stj)/2\n",
    "        Sij = mij / avg\n",
    "    \n",
    "    return Sij\n",
    "\n",
    "\n",
    "\n",
    "\"Returns the token of the headlines with removed stop words\"\n",
    "def getTokensList(n):\n",
    "    wordsWoSW = []\n",
    "    words = []\n",
    "    words = normalize(n)\n",
    "    words = re.split('\\W+',words)\n",
    "    for word in words:\n",
    "        if word in stop_words:\n",
    "            continue\n",
    "        wordsWoSW.append(word)\n",
    "        \n",
    "    return wordsWoSW\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\n",
    "\n",
    "\n",
    "\"MAIN FUNCTION\"\n",
    "def main():\n",
    "    root = Tk()\n",
    "    root.geometry('640x480')\n",
    "    root.title(\"URDU NEWS CLUSTERRING\")\n",
    "    \n",
    "    scrollbar = Scrollbar(root)\n",
    "    scrollbar.pack(side=RIGHT, fill=Y)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \"OnCLickViewListner: Trigger after the search Qeury\"\n",
    "    def OnClickViewListner():\n",
    "        inputNews = entry_1.get()\n",
    "        path = 'Urdu NEWS dataset\\\\'\n",
    "        headlines = headlineReader(path)\n",
    "        alfaz = splitWords(headlines)\n",
    "        processedHeadlines = removeStopwords(alfaz)\n",
    "        cluster = relatedNews(headlines,inputNews)\n",
    "        docu = documentReturn(path)\n",
    "        print(docu)\n",
    "        i = 0\n",
    "        fop = open(\"InputNews.txt\",\"w\",encoding=\"utf-8\")\n",
    "        \n",
    "       \n",
    "        \n",
    "        \"ClickOnViewListner for the document view\"\n",
    "        def open_url(url):\n",
    "            result = [s for s in docu if url[3:len(url)-1] in s]\n",
    "            rs = str(result)\n",
    "            ab =  \"F:\\\\Subjects\\\\Python-WORKSPACE\\\\UrduNewsClusterring\\\\\"\n",
    "            ab = ab + rs[2:len(rs)-2]\n",
    "            fp = open(ab.replace(\"\\\\\\\\\",\"\\\\\"),\"r\",encoding=\"utf-8\")\n",
    "            stri = fp.read()\n",
    "            \n",
    "            wind = Toplevel(root)\n",
    "            window = Text(wind,height = 200, width = 100)\n",
    "            window.pack()\n",
    "            window.insert(END,stri)\n",
    "            \n",
    "\n",
    "        for j,url in enumerate(cluster):\n",
    "            label=Label(root,text=url)\n",
    "            label.bind(\"<Button-1>\",lambda e,url=url:open_url(url))\n",
    "            label.pack()\n",
    "            fop.write(\"خبر\"+\": \"+str(i+1))\n",
    "            fop.write(str(url))\n",
    "            fop.write(\"\\n\")\n",
    "            i = i + 1\n",
    "            \n",
    "    \n",
    "    label_1 = Label(root, text=\"Enter Query\",font=('Courier',15))\n",
    "    label_1.pack()\n",
    "    entry_1 = Entry(root)    \n",
    "    entry_1.config(width=50)    \n",
    "    entry_1.pack()    \n",
    "    button_1 = Button(root,text='Search',command= OnClickViewListner)\n",
    "    button_1.pack()    \n",
    "    root.mainloop()\n",
    "\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b05bd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
